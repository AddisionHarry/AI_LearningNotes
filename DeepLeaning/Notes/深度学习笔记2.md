# 深度学习吴恩达老师课堂笔记（二）

## 2. 改善深层神经网络：超参数调试、正则化以及优化

### 2.1 深度学习实践

在机器学习中典型的训练集-验证集-测试集的数据划分比例是6:2:2，但是在深度学习领域，在**样本数据量足够大**的情况下可以降低验证集和测试集的数据比例，比如可以调节成`0.98 : 0.01 : 0.01`甚至更低。


在训练网络的时候最好需要保证训练集和测试集同分布，这样有利于网络表现出更好的性能。在深度学习网络中，如果不需要获得网络性能的无偏估计，那么不设置测试集只设置训练集和验证集也是可以被接受的。


如果训练出来一个网络，首先可以观察一下网络在训练集上的正确率，如果在训练集上表现也很差说明网络陷入欠拟合（高偏差问题），那么就需要考虑更换网络结构比如使用更深层的网络或者增长训练时间等来解决高偏差问题（这是最低标准）；在实现训练集上的高正确率以后就可以检测网络在测试集上的性能，如果网络在测试集上表现不是很好说明网络陷入过拟合（高方差问题），此时可以考虑使用更多的数据集或者加入正则化来解决，不过有的时候也可以考虑更换网络结构。


常见的正则化分为 L2 正则化和 L1 正则化，前者使用的是参数的二范数而后者使用的是一范数：
![两种正则化方法](../Pic/image7.png)
L1 正则化会导致参数的稀疏化（就是存在比较多的0），因此现在越来越多会使用 L2 正则化。而在描述矩阵的时候这个范数则被称为 Frobenius 范数，描述的是矩阵中每个元素的平方和。


加入正则化项以后的代价函数可以被写作：
$$
J(\boldsymbol{W}^{[1]},b^{[1]},\boldsymbol{W}^{[2]},b^{[2]},\cdots,\boldsymbol{W}^{[L]},b^{[L]})=\frac{1}{m}\sum_{i=1}^mL(\hat y^{(i)},y^{(i)})+\frac{\lambda}{2m}\sum_{l=1}^L||\boldsymbol{W}^{[l]}||_F^2\\
$$
